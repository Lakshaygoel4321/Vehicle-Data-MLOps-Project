# 🚀 Vehicle Data MLOps Project  

An end-to-end MLOps pipeline designed for vehicle data analysis using state-of-the-art tools and cloud services. This project showcases the full lifecycle of a Machine Learning model from development to deployment using robust CI/CD practices, cloud infrastructure, and containerization.  

---

## 🌟 Key Features  
- **Complete MLOps Pipeline:** From data ingestion to model deployment.  
- **Cloud Integration:** Uses AWS services (S3, EC2, ECR, IAM) for model storage and deployment.  
- **CI/CD Integration:** Automated testing, containerization, and deployment using GitHub Actions.  
- **Containerization:** Dockerized application for consistency across environments.  
- **Scalable Deployment:** Hosted on an AWS EC2 instance with public access.  

---

## 🛠️ Tech Stack and Tools  
- **Programming Language:** Python  
- **Frameworks and Libraries:** Streamlit, Docker, PyMongo, Scikit-learn, Pandas, NumPy  
- **Cloud Services:** AWS (S3, EC2, ECR, IAM)  
- **CI/CD:** GitHub Actions  
- **Containerization:** Docker  
- **Database:** MongoDB Atlas  

---

## ⚙️ Architecture Overview  
The project follows a modular and scalable MLOps architecture:  
1. **Data Ingestion:** Fetches data from MongoDB and transforms it into a Pandas DataFrame.  
2. **Data Validation and Transformation:** Validates schema and transforms data for model training.  
3. **Model Training:** Trains the model and saves the best-performing version.  
4. **Model Evaluation:** Evaluates model performance against a predefined threshold.  
5. **Model Deployment:** Deploys the model as a RESTful API using Docker and EC2.  
6. **CI/CD Pipeline:** Automates building, testing, and deployment using GitHub Actions and Docker.  

---

## 📂 Project Structure  
```plaintext
MLOPS-Project1/
├── src/
│   ├── pipeline/          # Training and prediction pipelines
│   ├── components/        # Data ingestion, validation, transformation
│   ├── entity/            # Configuration and artifact entities
│   ├── configuration/     # MongoDB and AWS configurations
│   ├── aws_storage/       # AWS S3 integration
│   └── app.py             # Main application file
├── notebook/              # Notebooks for EDA and MongoDB operations
├── static/                # Static files for the web app
├── template/              # HTML templates for Streamlit UI
├── .github/workflows/     # CI/CD configuration with GitHub Actions
│   └── aws.yaml           # CI/CD workflow file
├── requirements.txt       # Python dependencies
├── Dockerfile             # Docker configuration for containerization
└── README.md               # Project documentation (You're reading this!)  
```

---

## 🚀 Getting Started  
### Prerequisites  
- Python 3.10  
- MongoDB Atlas account  
- AWS account  
- Docker  
- GitHub account  

### Installation  
1. **Clone the repository:**  
```sh
git clone https://github.com/Lakshaygoel4321/MLOPS-Project1.git
cd MLOPS-Project1
```

2. **Create a virtual environment and activate it:**  
```sh
conda create -n vehicle python=3.10 -y
conda activate vehicle
```

3. **Install dependencies:**  
```sh
pip install -r requirements.txt
```

4. **Set up MongoDB Connection URL:**  
   - Go to MongoDB Atlas → Database → Get Connection String  
   - Replace `<username>` and `<password>` in the connection string.  
   - Export the URL as an environment variable:  
     ```sh
     export MONGODB_URL="your_connection_string"
     ```

---

## 🚀 Deployment  
### Docker Setup  
1. **Build Docker Image:**  
```sh
docker build -t vehicleproj:latest .
```

2. **Run Docker Container:**  
```sh
docker run -d -p 5000:5000 vehicleproj:latest
```

### CI/CD Pipeline  
- **Automated CI/CD** is set up using GitHub Actions (`.github/workflows/aws.yaml`) to:  
  - Build and push Docker images to Amazon ECR  
  - Deploy the application to an AWS EC2 instance  
- **Secrets Management:**  
  - Add the following secrets in GitHub:  
    - `AWS_ACCESS_KEY_ID`  
    - `AWS_SECRET_ACCESS_KEY`  
    - `AWS_DEFAULT_REGION`  
    - `ECR_REPO`  

---

## 🌐 Accessing the Application  
1. **EC2 Public IP Address:**  
   After deployment, access the app at:  
   ```plaintext
   http://<EC2-PUBLIC-IP>:5080
   ```
2. **Training Endpoint:**  
   The model can be trained using the `/training` route.  

---

## 📊 Screenshots and Demo  
- Coming soon! (Add relevant UI screenshots or a demo video link)  

---

## 🚀 CI/CD Workflow Overview  
This project uses a **GitHub Actions** workflow to automate the CI/CD pipeline:  
1. **Continuous Integration (CI):**  
   - Triggered on push to the `main` branch.  
   - Builds and pushes Docker images to Amazon ECR.  

2. **Continuous Deployment (CD):**  
   - Deploys the Docker container to an EC2 instance.  
   - Uses a self-hosted runner on the EC2 instance.  

---

## 📈 Challenges and Learnings  
- **Challenges:**  
  - Managing environment variables securely across multiple cloud services.  
  - Implementing a seamless CI/CD pipeline with GitHub Actions and AWS integration.  

- **Learnings:**  
  - Enhanced understanding of MLOps architecture and cloud deployments.  
  - Gained experience in building scalable ML pipelines using Docker and AWS.  

---

## 🚀 Future Improvements  
- Implement monitoring and alerting for model performance using AWS CloudWatch.  
- Add model versioning and A/B testing for continuous model improvements.  
- Integrate unit testing and code quality checks in the CI pipeline.  

---

## 👨‍💻 Author  
**Lakshay Goel**  
- [LinkedIn](https://www.linkedin.com/in/lakshay-goel/)  
- [GitHub](https://github.com/Lakshaygoel4321)  

---

## 📝 License  
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.  

---

## 🎉 Acknowledgements  
- Special thanks to the open-source community and the contributors of the libraries used in this project.  

